{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c7e803bcb692553a80f9fdded4c1a4f9a7897428"
   },
   "source": [
    "# MLDM Lab week 3: Neural Networks - Perceptron and Multi-Layer Perceptron (MLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> <font color=\"blue\"> Introduction </h3>\n",
    "\n",
    "In this lab session, we explore Perceptron and Multi-Layer Perceptron (MLP) using `sklearn`.\n",
    "\n",
    "We revisit the Iris and the Breast Cancer datasets from previous lab sessions and train Perceptron and MLP classifiers using these datasets. Please see the information regarding these datasets from previous two lab sessions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "da9c6cd47b5c79bed433cc47618a56837322db5d"
   },
   "source": [
    "<h3> <font color=\"blue\"> Lab goals</font> </h3>\n",
    "<p> 1.  Learn how to create and use a Perceptron. </p>\n",
    "<p> 2.  Learn how to create and use a MLP. </p>\n",
    "<p> 3.  Learn how to create ROC curves to evaluate and compare models. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\"> Training and evaluating a Perceptron \n",
    "In this experiment we re-visit the Iris dataset, however, instead of loading the dataset from a file or url, we load the dataset directly from the scikit-learn datasets. In this dataset, the third column represents the petal length, and the fourth column the petal width of the flower examples and the classes are already converted to integer labels where 0=Iris-Setosa, 1=Iris-Versicolor, 2=Iris-Virginica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, [2, 3]]\n",
    "y = iris.target\n",
    "\n",
    "print('Class labels:', np.unique(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing the training and test data by splitting the main dataset into 70% training and 30% test stes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Labels counts in y:', np.bincount(y))\n",
    "print('Labels counts in y_train:', np.bincount(y_train))\n",
    "print('Labels counts in y_test:', np.bincount(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features can be standardised using the `StandardScaler`. See <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\">`class sklearn.preprocessing.StandardScaler`</a> for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\"> Training a Perceptron \n",
    "    \n",
    "We train a Perceptron on the Iris dataset. In the first experiment we use simple and basic parameters. \n",
    "    \n",
    "More information about Perceptron parameters can be found from <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Perceptron.html\"> `sklearn.linear_model.Perceptron` </a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "ppn = Perceptron(eta0=0.1, random_state=1)\n",
    "ppn.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** You can replace `Perceptron(n_iter, ...)` by `Perceptron(max_iter, ...)` in scikit-learn >= 0.19. The `n_iter` parameter is used here deriberately, because some people still use scikit-learn 0.18."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ppn.predict(X_test_std)\n",
    "print('Misclassified examples: %d' % (y_test != y_pred).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy(test set): %.3f' % accuracy_score(y_test, y_pred))\n",
    "print('Accuracy (standardised test set): %.3f' % ppn.score(X_test_std, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\"> Training and evaluating a Multi-Layer Perceptron (MLP)\n",
    "In this experiment we re-visit the breast cancer dataset, however, instead of loading the dataset from scikit-learn datasets, we load the dataset from a csv file. Please download (and unzip) the breast cancer dataset from SurreyLearn and copy the file 'breast_cancer_data.csv' into your Jupyter working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "614080eef877a8cc3f436522abe889a14958d4dc"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "breast_cancer = pd.read_csv('breast_cancer_data.csv')\n",
    "# Dataset Shape\n",
    "print (breast_cancer.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Few Columns and Head Details\n",
    "breast_cancer.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a06977de599e1a2094e6d0b74f7e0c7ceef02165"
   },
   "source": [
    "<p> We need to specify the features which are used for machine learning. We need to remove the features which should be excluded, e.g. ID. We also need to specify the target feature, i.e. diagnosis class.\n",
    "    Feature Engineering is the way of extracting features from data and transforming them into formats that are suitable for Machine Learning algorithms.</p> Here we are going to remove certain unwanted features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "438a3421517af2feab182ceca38e2396bb10f05e"
   },
   "outputs": [],
   "source": [
    "# Features \"id\" and \"Unnamed: 32\" should be removed\n",
    "feature_names = breast_cancer.columns[2:-1]\n",
    "X = breast_cancer[feature_names]\n",
    "# the target feature, i.e. diagnosis class\n",
    "y = breast_cancer.diagnosis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ed083f7eaec1b4389b74fca255d68bc9930ab23b"
   },
   "source": [
    "<p>The traget feature in this dataset is included as a text value so it should be converted into a numerical value.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4a9999cf49909c36cc65261cd345776b02a407b6"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "class_le = LabelEncoder()\n",
    "# M -> 1 and B -> 0\n",
    "y = class_le.fit_transform(breast_cancer.diagnosis.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_cancer[feature_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1edc4bd8a9f5feaabff05088ef522a447ee666f2"
   },
   "source": [
    "### <font color=\"blue\"> Training a Multi-Layer Perceptron (MLP)\n",
    "We train a Multi-Layer Perceptron (MLP) on the breast cancer dataset. In the first experiment we use simple parameters which we will try to optimise later. \n",
    "    \n",
    "More information about MLP parameters can be found from <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html\"> `sklearn.neural_network.MLPClassifier` </a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and testing data preperation.\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, roc_auc_score, classification_report\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# Initializing the classifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(random_state=0, activation='logistic', hidden_layer_sizes=(5,), solver='adam', max_iter=100)\n",
    "clf.fit(X_train, y_train)\n",
    "clf_predict = clf.predict(X_test)\n",
    "# Accuracy factors\n",
    "print('acc for training data: {:.3f}'.format(clf.score(X_train, y_train)))\n",
    "print('acc for test data: {:.3f}'.format(clf.score(X_test, y_test)))\n",
    "print('MLP Classification report:\\n\\n', classification_report(y_test, clf_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can improve the accuracy of the MLP by tuning the parameters, e.g. increasing the 'hidden_layer_sizes' or 'max_iter'. Below we increase hidden_layer_sizes from 5 to 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPClassifier(random_state=0, activation='logistic', solver='adam', hidden_layer_sizes=(10,), max_iter=100)\n",
    "clf.fit(X_train, y_train)\n",
    "clf_predict = clf.predict(X_test)\n",
    "\n",
    "# Accuracy factors\n",
    "print('acc for training data: {:.3f}'.format(clf.score(X_train, y_train)))\n",
    "print('acc for test data: {:.3f}'.format(clf.score(X_test, y_test)))\n",
    "print('MLP Classification report:\\n\\n', classification_report(y_test, clf_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><font color=\"red\">Exercise 1 </font> </h3>\n",
    "<p>Repeat the experiment above and try to further improve the accuracy of the MLP by increasing 'max_iter'</p>\n",
    "\n",
    "<p>Use the code cell below to write your code for Excercise 1</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer to Exercise 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><font color=\"red\">Exercise 2 </font> </h3>\n",
    "<p>Repeat the experiment above using a Perceptron on the breast cancer dataset and compare the accuracy with the results from MLP.</p>\n",
    "\n",
    "<p>Use the code cell below to write your code for Excercise 2</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer to Exercise 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> <font color=\"blue\"> Receiver Operating Characteristic (ROC) curves </font> </h3>\n",
    "\n",
    "ROC curves are one of the most useful ways to evaluate and compare learning algorithms. Below we compare the performance of two MLP classifiers (i.e. MLP1 and MLP2) with different parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc curve and auc\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# generate a random prediction (majority class)\n",
    "ns_probs = [0 for _ in range(len(y_test))]\n",
    "# fit first model(MLP 1)\n",
    "clf1 = MLPClassifier(random_state=0, activation='logistic', hidden_layer_sizes=(5,), max_iter=100)\n",
    "clf1.fit(X_train, y_train)\n",
    "# fit second model(MLP 2)\n",
    "clf2 = MLPClassifier(random_state=0, activation='logistic', hidden_layer_sizes=(10,), max_iter=100)\n",
    "clf2.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# predict probabilities for different models\n",
    "lr_probs1 = clf1.predict_proba(X_test)\n",
    "lr_probs2 = clf2.predict_proba(X_test)\n",
    "\n",
    "# keep probabilities for the positive outcome only\n",
    "lr_probs1 = lr_probs1[:, 1]\n",
    "lr_probs2 = lr_probs2[:, 1]\n",
    "\n",
    "# calculate accuracy score for random prediction model\n",
    "ns_auc = roc_auc_score(y_test, ns_probs)\n",
    "\n",
    "# calculate accuracy score different MLP models\n",
    "lr_auc1 = roc_auc_score(y_test, lr_probs1)\n",
    "lr_auc2 = roc_auc_score(y_test, lr_probs2)\n",
    "\n",
    "# summarize scores\n",
    "print('Baseline (random guess): ROC AUC=%.3f' % (ns_auc))\n",
    "print('MLP 1 (hidden layer sizes=5): ROC AUC=%.3f' % (lr_auc1))\n",
    "print('MLP 2 (hidden layer sizes=10): ROC AUC=%.3f' % (lr_auc2))\n",
    "\n",
    "# calculate roc curves\n",
    "ns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)\n",
    "lr_fpr1, lr_tpr1, _ = roc_curve(y_test, lr_probs1)\n",
    "lr_fpr2, lr_tpr2, _ = roc_curve(y_test, lr_probs2)\n",
    "\n",
    "# plot the roc curve for the model\n",
    "pyplot.plot(ns_fpr, ns_tpr, linestyle='--', label='Baseline (random guess)')\n",
    "pyplot.plot(lr_fpr1, lr_tpr1, marker='.', label='MLP 1 (hidden layer sizes=5)')\n",
    "pyplot.plot(lr_fpr2, lr_tpr2, marker='.', label='MLP 2 (hidden layer sizes=10)')\n",
    "# axis labels\n",
    "pyplot.xlabel('False Positive Rate')\n",
    "pyplot.ylabel('True Positive Rate')\n",
    "# show the legend\n",
    "pyplot.legend()\n",
    "# show the plot\n",
    "pyplot.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><font color=\"red\">Exercise 3 </font> </h3>\n",
    "<p>Repeat the experiment above and define a new MLP classifier (named MLP 3) try to further improve the accuracy of the MLP 3 by changing the parameters, e.g. increasing 'hidden_layer_sizes' and 'max_iter'. What is the max accuracy you can get by tuning the parameters ?</p>\n",
    "\n",
    "<p>Use the code cell below to write your code for Excercise 3</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer to Exercise 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><font color=\"red\">Exercise 4 </font> </h3>\n",
    "<p>Repeat the experiment in Exercise 3 but instead of a new MLP classifier define a Perceptron (named P 1) on the same dataset (i.e. breast cancer) and compare the result with MLP 1 and MLP 2. What do you think might be the reason for the difference between the performance of the MLP classifiers and the Perceptron on this dataset? Try to chnage the Perceptron parameters (reduce the learning rate, Eta) and repeat the experiment. </p>\n",
    "\n",
    "<p>Use the code cell below to write your code for Exercise 4</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Answer to Exercise 4 \n",
    "# Hint: Unlike MLP, Perceptron doesn't have 'predict_proba' but you can implement it using CalibratedClassifierCV as shown below\n",
    "#\n",
    "# ppn = Perceptron(eta0=0.01, random_state=0, max_iter=100)\n",
    "# ppn = CalibratedClassifierCV(ppn)\n",
    "#\n",
    "# and then you can call ppn.predict_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><font color=\"red\">Save your notebook after completing the exercises and submit it to SurreyLearn (Assessments -> Assignments -> Lab Exercises - Week 3) as a python notebook file in ipynb formt. </h3>\n",
    "<h3><font color=\"red\">Deadline: 4:00pm Thursday 29 Feb  </h3> "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
